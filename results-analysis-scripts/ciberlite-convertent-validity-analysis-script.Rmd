---
title: "CIBERlite: convergent validity"
author: "Gjalt-Jorn Peters & Rik Crutzen"
date: "`r format(Sys.time(), '%H:%M:%S on %Y-%m-%d %Z (GMT%z)')`"
output:
  html_document:
    toc: true
---

# Introduction

## Status of this file

This is the R Markdown file for the "CIBERlite: convergent validity" study. This study is a project of the Academy of Behavior Change. The canonical URL for this study is https://ciberlite.com/convergent-validity. Initially, this will resolve to the study's Open Science Framework repository (https://osf.io/pemfz/), but in time it may point to a website to facilitate CIBERlite implementation by prevention organisations. The study's OSF repository (repo) synchronises with the GitHub repo at https://github.com/academy-of-behavior-change/ciberlite-convergent-validity.

This R Markdown file is very much a living document, and as such, also contains all R code. For the CIBERlite plot, scroll down to the CIBERlite plots heading.

Note that because this is a living project, you will probably need the most up-to-date version of the `userfriendlyscience` package (*if* that has been submitted to CRAN yet). See https://userfriendlyscience.com for instructions as to how to install it.

## Background of the project

CIBERlite is a project where we aim to provide an easy-to-use and apply rudimentary approximation of a determinant study, so that practitioners (e.g. for preventions organisations) can feasibly quickly get an idea of which determinants are the most relevant in predicting a given target behavior in a given target population. To develop this method, we conduct a study comparing relative determinant levels for eight behaviors in the general population.

A second goal of CIBERlite, but only one that only emerged as we were working on this project, is to work towards a framework for calibrating determinant operationalisations over behaviors and populations.

The preregistration form for this study is at https://osf.io/pemfz/register/hvkzr. That is a good place to start before reading further.

## License of these materials

This file and the other materials in the OSF and GitHub repo's associated with this project are licensed under the Creative Commons attribution share alike license (CC-BY-NC-SA; see http://creativecommons.org/licenses/by-nc-sa/4.0/). This means that you are allowed to copy and distribute these files freely, but youâ€™re not allowed to sell them. It also means that if you create derivative works (i.e. if you remix, transform, or build upon the material), you must distribute your contributions under the same license as the original.

# Setup of R environment

Here, we configure some settings and load the required R packages.

```{r setup}

knitr::opts_chunk$set(echo = TRUE);
options(ufs.debug = FALSE);

require('userfriendlyscience');
safeRequire('here');
safeRequire('data.tree');
safeRequire('tidyverse');
safeRequire('gridExtra');
safeRequire('readODS');

dataPath <- here::here('results-data-raw');
processedDataPath <- here::here('results-data-processed');
outputPath <- here::here('results-output');

privateDataFileRegEx <- 'survey_797479_R_data_file_\\[PRIVATE-version]';
publicDataFileRegEx <- 'survey_797479_R_data_file_\\[PUBLIC-version]';
dataLoadScriptName <- 'survey_797479_R_syntax_file.R';

categoricalQuestions <- c('sex',
                          'education');

dataDeletionVarCode <- "dataMustBeDeleted";
dataDeletionSubQuestionCode <- "delete";
dataDeletionVarValue <- "2";
privateFileIdentificationString <- "PRIVATE-";
publicFileIdentificationString <- "PUBLIC-";

### These are the behaviors in this study

behaviors <- c("alcohol", "coffee", "smoking",
               "exercise", "marathon");

```

# Determinant structures

This command builds the determinant structures that we will analyse. This uses very much in-progress code from the `userfriendlyscience` package that leverages the `data.tree` package to build a hierarchy of determinants and sub-determinants.

```{r}

detStruct_original <-
  lapply(behaviors,
         function(behav) {
  return(determinantStructure(behav,
                              list(behaviorRegEx = behav),
                              determinantVar("intention_original",
                                             "_int\\w+",
                                             determinantVar("attitude_original",
                                                            "_att\\w+"),
                                             determinantVar("perceivedNorm_original",
                                                            "_pn\\w+"),
                                             determinantVar("perceivedBehavioralControl_original",
                                                            "_pbc\\w+"))));
});

detStruct_short <-
  lapply(behaviors,
         function(behav) {
  return(determinantStructure(behav,
                              list(behaviorRegEx = behav),
                              determinantVar("intention_short",
                                             "_intPlan",
                                             determinantVar("attitude_short",
                                                            "_attExperPleasant|_attInstrGood"),
                                             determinantVar("perceivedNorm_short",
                                                            "_pnInjunctiveApprove|_pnDescriptiveLikeMe"),
                                             determinantVar("perceivedBehavioralControl_short",
                                                            "_pbcCapacityConfidenc|_pbcControlUpToMe"))));
});

```

# Data import and merging

This includes sanitizing the private data files for publication.

```{r}

########################################################################
###
### Import data
###
########################################################################
###
### First delete the data from students who indicated they want their
### data destroyed (note that this private data file is excluded from
### synchronization with the GitHub repository, and therefore the OSF
### repository, using .gitignore)
###
########################################################################

### Get a list of all data files in data directory
privateDataFiles <-
  list.files(dataPath);

### Select only those matching the regular expression for
### Open University data files
privateDataFiles <-
  grep(privateDataFileRegEx,
       privateDataFiles,
       value=TRUE);

if (length(privateDataFiles) > 0) {
  ### Private data files are present; this means we run on the PC
  ### of one of the researchers. That means we should sanitize the
  ### datasets and prepare them for publishing.
  
  dataDeletionVarName <- paste0(dataDeletionVarCode,
                              "_",
                              dataDeletionSubQuestionCode);

  ### Loop through the files
  for (currentFilename in privateDataFiles) {
    
    ### Run within local, temporary namespace (so that all variables
    ### are deleted afterwards)
    local({
    
      ### First read in a temporary version of the data
      dat <-
        importLimeSurveyData(datafile = file.path(dataPath,
                                                  currentFilename),
                             datafileRegEx = privateDataFileRegEx,
                             scriptfile = file.path(dataPath,
                                                    dataLoadScriptName),
                             categoricalQuestions = categoricalQuestions);
      
      ### Then get the position of the variable used to indicate whether
      ### data should be deleted:
      dataDeletionVarIndex <-
        grep(dataDeletionVarName, names(dat));
      
      ### Then construct the regular expression for matching the lines in
      ### the dataset that contain the data of participants who indicated
      ### they wanted their data deleted. A regular expression of the
      ### following form is constructed:
      ###
      ### (?:"[^"]*",){75}"2"
      ###
      ### The '75' is the index minus one, and the '2' the value indicating
      ### that data should be deleted. This regular expression matches any
      ### value between a pair of double quotes followed by a comma exactly
      ### 75 times; then matches a '2' between pair of double quotes. This
      ### pair of double quotes contains the value of the 76th variable (so,
      ### in this example, the value of the variable indicating whether data
      ### should be deleted), and therefore, this regular expression matches
      ### all lines containing data that should be deleted.
      
      dataDeletionRegEx <-
        paste0('(?:"[^"]*",){',
               dataDeletionVarIndex-1,
               '}"',
               dataDeletionVarValue,
               '"');
  
      ### Then read the datafile as character vector
      fullPrivateDataFile <-
        readLines(file.path(dataPath,
                            currentFilename));
      cat0("\n\nRead data file '", currentFilename, "'.\n\n");
  
      ### Get indices of lines that have to be deleted
      linesToDelete <- grep(dataDeletionRegEx,
                            fullPrivateDataFile);
      
      ### Log deletion
      cat0("Identified ", length(linesToDelete), " participants who ",
           "indicated they want their data to be deleted, specifically, ",
           "the following lines of the original raw dataset:\n\n",
           vecTxtQ(linesToDelete));
      
      ### Delete those lines
      if (length(linesToDelete) > 0) {
        fullPublicDataFile <- fullPrivateDataFile[-linesToDelete];
      } else {
        fullPublicDataFile <- fullPrivateDataFile;
      }
  
      ### Construct new filename to write public version of data to
      newTmpFilename <- sub(privateFileIdentificationString,
                            publicFileIdentificationString,
                            currentFilename,
                            fixed=TRUE);
      
      ### Store new datafile
      writeLines(fullPublicDataFile,
                 file.path(dataPath,
                           newTmpFilename));
  
      cat0("\n\nStored data file '", newTmpFilename, "'.\n\n");
  
    });  ### End local namespace
  
  }
}

########################################################################
### Import data from public version of the survey
########################################################################

dat.raw <-
  importLimeSurveyData(dataPath = dataPath,
                       datafileRegEx = publicDataFileRegEx,
                       scriptfile = file.path(dataPath,
                                              dataLoadScriptName),
                       categoricalQuestions = categoricalQuestions);

### Verify that no entries were read where people indicated they wanted
### their data removed
if (any(dat.raw[, dataDeletionVarName]==dataDeletionVarValue, na.rm=TRUE)) {
  stop("The public data contains data from people who indicated they ",
       "wanted their data to be removed!");
} else {
  ### Delete variable storing whether people want their data deleted,
  ### so that the data can be easily merged with the dataset from
  ### ondrzk.nl
  dat.raw[, grepl(dataDeletionVarCode,
                  names(dat.raw))] <- NULL;
}

dat <- dat.raw;

```

# Analyses

The aim of this study is to explore the convergent validity of the brief direct measures of the four main constructs as defined in the Reasoned Action Approach: intention, attitude, perceived norms and perceived behavioral control. To this end we compute the correlation coefficients of the original and the brief measures.

```{r results="asis"}

### Add variables names of the determinants' measures and compute
### means where necessary

### Original measures
for (i in seq_along(detStruct_original)) {
  detStructAddVarNames(detStruct_original[[i]], names(dat));
  dat <- detStructComputeScales(detStruct_original[[i]],
                                dat);
}

### Short measures
for (i in seq_along(detStruct_short)) {
  detStructAddVarNames(detStruct_short[[i]], names(dat));
  dat <- detStructComputeScales(detStruct_short[[i]],
                                dat);
}

### Loop through behaviors
for (i in seq_along(behaviors)) {
  cat0("\n\n## ", behaviors[i], "\n\n");

  cat0("\n\n### Intention\n\n");
  
  cor.test(dat[, detStruct_original[[i]]$intention_original$scaleVarName],
           dat[, detStruct_short[[i]]$intention_short$scaleVarName])$conf.int;

  cat0("\n\n### Attitude\n\n");
  
  cor.test(dat[, detStruct_original[[i]]$intention_original$attitude_original$scaleVarName],
           dat[, detStruct_short[[i]]$intention_short$attitude_short$scaleVarName])$conf.int;

  cat0("\n\n### Perceived Norms\n\n");
  
  cor.test(dat[, detStruct_original[[i]]$intention_original$perceivedNorms_original$scaleVarName],
           dat[, detStruct_short[[i]]$intention_short$perceivedNorms_short$scaleVarName])$conf.int;

  cat0("\n\n### Perceived Behavioral Control\n\n");
  
  cor.test(dat[, detStruct_original[[i]]$intention_original$perceivedBehavioralControl_original$scaleVarName],
           dat[, detStruct_short[[i]]$intention_short$perceivedBehavioralControl_short$scaleVarName])$conf.int;

}

```


